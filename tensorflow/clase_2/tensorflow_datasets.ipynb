{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSV_OlCFKOD"
      },
      "source": [
        "# Entrenando una red neuronal en MNIST con Keras\n",
        "\n",
        "Este sencillo ejemplo demuestra cómo conectar conjuntos de datos de TensorFlow (TFDS) a un modelo de Keras.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8y9ZkLXmAZc"
      },
      "source": [
        "Copyright 2020 Los autores de los conjuntos de datos de TensorFlow, con licencia Apache, versión 2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGw9EgE0tC0C"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/JhennerTigreros/UNICIENCIA-INTRO-PROGRAMACION/blob/master/tensorflow/clase_2/tensorflow_datasets.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTBSvHcSLBzc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjI6VgOBf0v0"
      },
      "source": [
        "\n",
        "## Paso 1: cree su canal de entrada\n",
        "\n",
        "Comience por crear un canal de entrada eficiente utilizando los consejos de:\n",
        "* The [Performance tips](https://www.tensorflow.org/datasets/performances) guide\n",
        "* The [Better performance with the `tf.data` API](https://www.tensorflow.org/guide/data_performance#optimize_performance) guide\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3aH3vP_XLI8"
      },
      "source": [
        "### Cargar un conjunto de datos\n",
        "Cargue el conjunto de datos MNIST con los siguientes argumentos:\n",
        "\n",
        "* `shuffle_files=True`: Los datos de MNIST solo se almacenan en un solo archivo, pero para conjuntos de datos más grandes con múltiples archivos en disco, es una buena práctica mezclarlos durante el entrenamiento.\n",
        "* `as_supervised=True`: Devuelve una tupla `(img, label)` en lugar de un diccionario `{'image': img, 'label': label}`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUMhCXhFXdHQ"
      },
      "outputs": [],
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgwCFAcWXQTx"
      },
      "source": [
        "### Construir una tubería de entrenamiento\n",
        " \n",
        "Aplique las siguientes transformaciones:\n",
        "\n",
        "* `tf.data.Dataset.map`: TFDS proporciona imágenes de tipo `tf.uint8`, mientras que el modelo espera `tf.float32`. Por lo tanto, necesita normalizar las imágenes.\n",
        "* `tf.data.Dataset.cache`: Al ajustar el conjunto de datos en memoria, cacheelo antes de mezclarlo para un mejor rendimiento.<br/>\n",
        "__Nota:__ Las transformaciones aleatorias deben aplicarse después de almacenar en caché.\n",
        "* `tf.data.Dataset.shuffle`: Para una verdadera aleatoriedad, establezca el búfer de mezcla al tamaño completo del conjunto de datos.<br/>\n",
        "__Nota:__ Para conjuntos de datos grandes que no caben en memoria, use `buffer_size=1000` si su sistema lo permite.\n",
        "* `tf.data.Dataset.batch`: Agrupe los elementos del conjunto de datos después de mezclarlos para obtener lotes únicos en cada época.\n",
        "* `tf.data.Dataset.prefetch`: Es una buena práctica terminar la tubería prefetching [para el rendimiento](https://www.tensorflow.org/guide/data_performance#prefetching).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haykx2K9XgiI"
      },
      "outputs": [],
      "source": [
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "ds_train = ds_train.batch(128)\n",
        "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbsMy4X1XVFv"
      },
      "source": [
        "### Construir una tubería de evaluación\n",
        "\n",
        "Tu tubería de pruebas es similar a la tubería de entrenamiento con pequeñas diferencias:\n",
        "\n",
        " * No necesitas llamar a `tf.data.Dataset.shuffle`.\n",
        " * El almacenamiento en caché se realiza después de la agrupación en lotes porque los lotes pueden ser los mismos entre épocas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0KjuDf7XiqY"
      },
      "outputs": [],
      "source": [
        "ds_test = ds_test.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.batch(128)\n",
        "ds_test = ds_test.cache()\n",
        "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTFoji3INMEM"
      },
      "source": [
        "## Paso 2: Crear y entrenar el modelo\n",
        "\n",
        "Conecte el pipeline de entrada de TFDS a un modelo simple de Keras, compile el modelo y entrénelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWqxdmS1NLKA"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    ds_train,\n",
        "    epochs=6,\n",
        "    validation_data=ds_test,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's first import matplotlib to help us plot the images\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Fetch one batch of the test data\n",
        "for test_images, test_labels in ds_test.take(1):\n",
        "    # Take one random image from the batch\n",
        "    random_index = np.random.randint(0, test_images.shape[0])\n",
        "    test_image = test_images[random_index].numpy().squeeze()\n",
        "    test_label = test_labels[random_index].numpy()\n",
        "\n",
        "# Plot the test image\n",
        "plt.figure()\n",
        "plt.imshow(test_image, cmap=plt.cm.binary)\n",
        "plt.title('Actual Label: ' + str(test_label))\n",
        "plt.show()\n",
        "\n",
        "# Predict the label of the test image\n",
        "prediction = model.predict(tf.expand_dims(test_image, 0))\n",
        "\n",
        "# Print the predicted and actual label\n",
        "print('Predicted label:', np.argmax(prediction))\n",
        "print('Actual label:', test_label)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "tensorflow/datasets",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
